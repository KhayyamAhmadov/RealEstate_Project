{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                       # HTML və XML-dən məlumat çıxarmaq üçün\n",
    "from selenium import webdriver                                      # Brauzeri avtomatik idarə etmək üçün\n",
    "from selenium.webdriver.chrome.service import Service               # ChromeDriver-i başlatmaq üçün\n",
    "from selenium.webdriver.common.by import By                         # HTML elementlərini axtarmaq üçün (məs: By.CLASS_NAME)\n",
    "from webdriver_manager.chrome import ChromeDriverManager            # ChromeDriver versiyasını avtomatik endirmək üçün\n",
    "from selenium.webdriver.chrome.options import Options               # Chrome brauzerinə xüsusi ayarlar vermək üçün\n",
    "from selenium.webdriver.support.ui import WebDriverWait             # Elementlərin yüklənməsini gözləmək üçün\n",
    "from selenium.webdriver.support import expected_conditions as EC    # Müəyyən şərtlər ödənənə qədər gözləmək üçün\n",
    "from selenium.common.exceptions import TimeoutException             # Vaxt aşımı xətasını idarə etmək üçün\n",
    "from selenium.webdriver.common.keys import Keys                     # Klaviatura düymələrini simulyasiya etmək üçün (məs: ENTER)\n",
    "import time                                                         # Kodda gecikmə vermək üçün (məs: time.sleep)\n",
    "import pandas as pd                                                 # Verilənlərlə işləmək üçün (DataFrame, CSV və s.)\n",
    "import re                                                           # Mətn təmizləmək, regex (müntəzəm ifadələr) ilə işləmək üçün\n",
    "import pyodbc                                                       # SQL Server (və digər ODBC dəstəkləyən verilənlər bazaları) ilə bağlantı qurmaq üçün\n",
    "from sqlalchemy import create_engine                                # SQLAlchemy ilə verilənlər bazasına bağlantı yaratmaq və pandas ilə işləmək üçün\n",
    "import requests\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import queue\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import Thread\n",
    "from bs4 import NavigableString\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "raw_data = queue.Queue()\n",
    "cleaned_data = queue.Queue()\n",
    "list_data = []\n",
    "\n",
    "\n",
    "\n",
    "def scrap():\n",
    "    base_urls = ['https://arenda.az/filtirli-axtaris/?home_search=1&lang=1&site=1&home_s=1&elan_novu%5B1%5D=1&elan_novu%5B2%5D=2&elan_novu%5B3%5D=3&emlak_novu%5B370%5D=370&emlak_novu%5B371%5D=371&emlak_novu%5B5%5D=5&emlak_novu%5B861%5D=861&emlak_novu%5B94%5D=94&emlak_novu%5B8%5D=8&emlak_novu%5B270%5D=270&emlak_novu%5B854%5D=854&price_min=&price_max=&axtar=&sahe_min=&sahe_max=&mertebe_min=&mertebe_max=&y_mertebe_min=&y_mertebe_max=']\n",
    "\n",
    "    def scrape_url(current_url):\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        driver.maximize_window()\n",
    "        # linklerin tekrarlanmasinin qarsisini almaq\n",
    "        see_link = set()\n",
    "        print(f\"\\n{current_url} üzrə toplanir\")\n",
    "        \n",
    "        for i in range(1, 1001):\n",
    "            # Səhifə URL-ni qurmaq\n",
    "            url = f\"https://arenda.az/filtirli-axtaris/{i}/?home_search=1&lang=1&site=1&home_s=1&elan_novu%5B1%5D=1&elan_novu%5B2%5D=2&elan_novu%5B3%5D=3&emlak_novu%5B370%5D=370&emlak_novu%5B371%5D=371&emlak_novu%5B5%5D=5&emlak_novu%5B861%5D=861&emlak_novu%5B94%5D=94&emlak_novu%5B8%5D=8&emlak_novu%5B270%5D=270&emlak_novu%5B854%5D=854&price_min=&price_max=&axtar=&sahe_min=&sahe_max=&mertebe_min=&mertebe_max=&y_mertebe_min=&y_mertebe_max=\"\n",
    "            # Səhifə yükləmə cəhdləri\n",
    "            for attempt in range(2):  \n",
    "                try:\n",
    "                    driver.set_page_load_timeout(45)\n",
    "                    driver.get(url)\n",
    "                    break\n",
    "                except TimeoutException:\n",
    "                    print(f\"{i}. səhifə - Cəhd {attempt+1}: vaxt limiti keçdi\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"[id^='elan_'] > a\")))\n",
    "            except TimeoutException:\n",
    "                print(f\"{i}. səhifə yüklənmədi, keçilir...\")\n",
    "                continue\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Elan linklərinin tapılması\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, \"[id^='elan_'] > a\")\n",
    "            links = [e.get_attribute(\"href\") for e in elements if e.get_attribute(\"href\")]\n",
    "            \n",
    "            if not links:\n",
    "                print(f\"{current_url} - Səhifə {i} üçün elan tapılmadı\")\n",
    "                continue\n",
    "\n",
    "            # Tapılan elan linklerinden melumatlarin toplanmasi\n",
    "            for link in links:\n",
    "                if not (\"/satilir\" in link or \"/kiraye\" in link):\n",
    "                    continue\n",
    "\n",
    "                # link gorulubse , kec\n",
    "                if link in see_link:\n",
    "                    continue\n",
    "\n",
    "                # Gorulmus linkler see_link - e elave edilir\n",
    "                see_link.add(link)\n",
    "\n",
    "                # Elan səhifəsinə daxil olmaq\n",
    "                for attempt in range(2):\n",
    "                    try:\n",
    "                        driver.set_page_load_timeout(45)\n",
    "                        driver.get(link)\n",
    "                        break\n",
    "                    except TimeoutException:\n",
    "                        print(f\"Elan səhifəsi {link} - Cəhd {attempt+1}: vaxt limiti keçdi\")\n",
    "                        time.sleep(5)\n",
    "                \n",
    "                # Elanın məlumatlarının yüklənməsini gözləyir\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"h1\")))\n",
    "                except TimeoutException:\n",
    "                    print(f\"Elan yüklənmədi: {link}\")\n",
    "                    continue        \n",
    "            \n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                data = {\"URL\": link}\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # ID\n",
    "                ann_id = soup.find('div', class_='elan_e_kodu').find('strong')\n",
    "                data['ListingID'] = ann_id.text.strip() if ann_id else None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # Elan adi \n",
    "                announce = soup.find(\"h1\", {\"class\":\"elan_title\"})\n",
    "                data['ListingName'] = announce.text.strip() if announce else None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # Labels\n",
    "                labels = soup.find(\"ul\", class_=\"elan_adr_list full\")  # tək 'ul' tapırıq, ona görə find istifadə olunur\n",
    "                data[\"Labels\"] = [li.get_text(strip=True) for li in labels.find_all(\"li\")] if labels else []\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # Category \n",
    "                category = soup.find(\"h2\", {\"class\":\"full elan_in_title_link elan_main_title\"})\n",
    "                data[\"CategoryID\"] = category.text.strip() if category else None\n",
    "\n",
    "\n",
    "                #-------------------------------------------------------------------------\n",
    "                # Tarix\n",
    "                date = soup.find(\"p\", string=lambda text: text and \"Elanın tarixi\" in text)\n",
    "                data['ListingDate'] = date.text.strip() if date else None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # Aciqlama\n",
    "                description = soup.find(\"div\", {\"class\":\"full elan_info_txt\"})\n",
    "                data['Description'] = description.text.strip() if description else None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # unvan \n",
    "                address = soup.find(\"span\", {\"class\":\"elan_unvan_txt\"})\n",
    "                data['Address'] = address.text.strip() if address else None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # Melumat bloku\n",
    "                ul = soup.find('ul', {\"class\":\"full elan_property_list\"})\n",
    "                links = ul.find_all('a')\n",
    "\n",
    "                data['CountRoom'] = None\n",
    "                data['FieldAreaSqm'] = None\n",
    "                data['AreaInSot'] = None\n",
    "                data['Floor'] = None\n",
    "                data['Title'] = \"yoxdur\"  # default olaraq kupça yoxdur\n",
    "\n",
    "                for a in links:\n",
    "                    text = a.text.strip()\n",
    "\n",
    "                    if \"otaq\" in text and data['CountRoom'] is None:\n",
    "                        data['CountRoom'] = text\n",
    "\n",
    "                    if \"sot\" in text and data['AreaInSot'] is None:\n",
    "                        data['AreaInSot'] = text\n",
    "\n",
    "                    if (\"mərtəbəli\" in text or \"mərtəbə\" in text) and data['Floor'] is None:\n",
    "                        data['Floor'] = text\n",
    "\n",
    "                    if \"m2\" in text and data['FieldAreaSqm'] is None:\n",
    "                        data['FieldAreaSqm'] = text\n",
    "\n",
    "                    if \"Kupça (Çıxarış)\" in text:\n",
    "                        data['Title'] = \"var\"\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # Qiymet\n",
    "                price = soup.find(\"p\", {\"class\":\"full\"})\n",
    "                data['Price'] = price.text.strip() if price else None\n",
    "\n",
    "                # price_p = soup.find(\"p\", class_=\"full m-0\")\n",
    "\n",
    "                # if price_p:\n",
    "                #     for content in price_p.contents:\n",
    "                #         if isinstance(content, NavigableString):\n",
    "                #             data['Price'] = content.strip()\n",
    "                #             break\n",
    "                # else:\n",
    "                #     data['Price'] = None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # 1 kv.m\n",
    "                pricesqm = soup.find(\"span\", {\"class\":\" elan_new_prop_span elan_new_prop_top_span\"})\n",
    "                data['PricePerSqm'] = pricesqm.strip() if pricesqm else None\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                # nomre\n",
    "                salesperson = soup.find(\"div\", {\"class\":\"new_elan_user_info full\"}).find('p')\n",
    "                data['SalesPerson'] = salesperson.text.strip() if salesperson else None\n",
    "\n",
    "                #---------------------------------------------------------------------------\n",
    "                # contact \n",
    "                contact = soup.find(\"a\", {\"class\":\"elan_in_tel\"})\n",
    "                data['Contact'] = contact.text.strip() if contact else None\n",
    "\n",
    "\n",
    "                #----------------------------------------------------------------------------\n",
    "                lat_input = soup.find(\"input\", {\"id\": \"lat\"})\n",
    "                lon_input = soup.find(\"input\", {\"id\": \"lon\"})\n",
    "\n",
    "                data['Latitude'] = lat_input.get('value') if lat_input else None\n",
    "                data['Longitude'] = lon_input.get('value') if lon_input else None\n",
    "\n",
    "\n",
    "                #----------------------------------------------------------------------------\n",
    "                # images\n",
    "                images = soup.find_all(\"img\", {\"class\": \"translate\"})\n",
    "                data['Images'] = [img['src'] for img in images if img.get('src')]\n",
    "\n",
    "\n",
    "                #--------------------------------------------------------------------------\n",
    "                list_data.append(data)\n",
    "\n",
    "                df = pd.DataFrame([data])\n",
    "                raw_data.put(df)\n",
    "\n",
    "                \n",
    "                #--------------------------------------------------------------------------\n",
    "                print(f\"Sehife {i}. Ümumi {len(list_data)} elan toplandı.\")\n",
    "\n",
    "\n",
    "        driver.quit()\n",
    "    with ThreadPoolExecutor(max_workers=len(base_urls)) as executor:\n",
    "        executor.map(scrape_url, base_urls)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(raw):\n",
    "    df = raw.copy()\n",
    "\n",
    "    df['ListingID'] = pd.to_numeric(df['ListingID'], errors='coerce')\n",
    "    df['ListingID'] = df['ListingID'].apply(lambda x: '505' + str(int(x)) if pd.notna(x) else x) \n",
    "    df['ListingID'] = pd.to_numeric(df['ListingID'], errors='coerce').astype(\"Int64\")\n",
    "\n",
    "\n",
    "    df['Date'] = pd.to_datetime(\n",
    "    df['ListingDate'].str.replace('Elanın tarixi: ', '', regex=False), format='%d.%m.%Y')\n",
    "\n",
    "    # 1. SalesType sutunu yaratmaq\n",
    "    df['SalesType'] = df['ListingName'].apply(lambda x: 0 if 'Kirayə' in str(x) else 1 if 'Satılır' in str(x) else np.nan)\n",
    "    df['SalesType'] = df['SalesType'].astype('Int8')  # bit üçün Int8 istifadə edirik\n",
    "\n",
    "    # 2. DailyRent sütunu: case-insensitive və sadə məntiq\n",
    "    df['DailyRent'] = df['ListingName'].apply(\n",
    "        lambda x: 1 if 'günlük' in str(x).lower() else 0 if 'aylıq' in str(x).lower() else np.nan)\n",
    "    df['DailyRent'] = df['DailyRent'].astype('Int64')\n",
    "\n",
    "    # 3. CategoryID-ni dəyişdirmək\n",
    "    category_mapping = {\n",
    "        'Yeni Tikili': 2,\n",
    "        'Köhnə Tikili': 3,\n",
    "        'Həyət evi/villa': 4,\n",
    "        'Bağ evi': 4,\n",
    "        'Obyekt': 8,\n",
    "        'Ofis': 5,\n",
    "        'Torpaq': 7,\n",
    "        'Qaraj': 6}\n",
    "\n",
    "    # Mətnləri dəyiş\n",
    "    for key, value in category_mapping.items():\n",
    "        df.loc[df['CategoryID'].astype(str).str.contains(key, na=False), 'CategoryID'] = value\n",
    "    df['CategoryID'] = pd.to_numeric(df['CategoryID'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # 4. Description sutunundan emoji və əlavə simvolları silmək\n",
    "    df['Description'] = df['Description'].apply(lambda x: \n",
    "        re.sub(r'[^\\w\\s\\-.,!?()]+', '', str(x), flags=re.UNICODE).strip() if pd.notna(x) else x)\n",
    "\n",
    "    # 5. CountRoom - \"otaq\" sözünü silmək\n",
    "    df['CountRoom'] = df['CountRoom'].apply(lambda x: \n",
    "        int(re.sub(r'otaq', '', str(x), flags=re.IGNORECASE).strip()) if pd.notna(x) and \n",
    "        re.sub(r'otaq', '', str(x), flags=re.IGNORECASE).strip().isdigit() else np.nan)\n",
    "    df['CountRoom'] = df['CountRoom'].astype('Int64')\n",
    "\n",
    "    # 6. FieldAreaSqm - \"m2\" silmək və float64-ə çevirmək\n",
    "    # df['FieldAreaSqm'] = df['FieldAreaSqm'].apply(lambda x: \n",
    "    #     float(re.sub(r'm2?', '', str(x), flags=re.IGNORECASE).strip()) if pd.notna(x) and \n",
    "    #     re.sub(r'm2?', '', str(x), flags=re.IGNORECASE).strip().replace('.','').isdigit() else np.nan)\n",
    "    # df['FieldAreaSqm'] = df['FieldAreaSqm'].astype('float64')\n",
    "\n",
    "    df['FieldAreaSqm_clean'] = (\n",
    "        df['FieldAreaSqm']\n",
    "        .astype(str)\n",
    "        .str.replace(r'[^0-9.]', '', regex=True)\n",
    "        .replace(r'^$', np.nan, regex=True))\n",
    "    df['FieldAreaSqm_clean'] = pd.to_numeric(df['FieldAreaSqm_clean'], errors='coerce')\n",
    "    df['FieldAreaSqm'] = df['FieldAreaSqm_clean'].astype('float64')\n",
    "\n",
    "\n",
    "    # 7. Floor sutunundan FloorNumber və TotalFloors yaratmaq\n",
    "    floor_info = df['Floor'].apply(lambda x: \n",
    "        re.search(r'(\\d+)\\s*/\\s*(\\d+)', str(x)).groups() if pd.notna(x) and \n",
    "        re.search(r'(\\d+)\\s*/\\s*(\\d+)', str(x)) else (np.nan, np.nan))\n",
    "\n",
    "    df['FloorNumber'] = [int(info[0]) if info[0] is not np.nan else np.nan for info in floor_info]\n",
    "    df['TotalFloors'] = [int(info[1]) if info[1] is not np.nan else np.nan for info in floor_info]\n",
    "\n",
    "    df['FloorNumber'] = df['FloorNumber'].astype('Int64')\n",
    "    df['TotalFloors'] = df['TotalFloors'].astype('Int64')\n",
    "\n",
    "    # Floor sutununu silmək\n",
    "    df = df.drop('Floor', axis=1)\n",
    "\n",
    "    # 8. Title sutununu boolean-a çevirmək\n",
    "    df['Title'] = df['Title'].apply(lambda x: False if str(x).lower() in ['yoxdur', 'nan', 'none'] else True)\n",
    "    df['Title'] = df['Title'].astype('bool')\n",
    "\n",
    "    df['Price'] = pd.to_numeric(\n",
    "        df['Price'].astype(str).str.replace(r'[^\\d.]', '', regex=True), \n",
    "        errors='coerce').astype('Int64')\n",
    "\n",
    "    # 10. PricePerSqm sutununu təmizləmək\n",
    "    df['PricePerSqm'] = df['PricePerSqm'].apply(lambda x: \n",
    "        int(''.join(re.findall(r'\\d+', str(x))[:2])) if pd.notna(x) and \n",
    "        re.findall(r'\\d+', str(x)) else np.nan)\n",
    "    df['PricePerSqm'] = df['PricePerSqm'].astype('Int64')\n",
    "\n",
    "    # 11. SalesPerson sutunundan SellerType yaratmaq\n",
    "    df['SellerType'] = df['SalesPerson'].apply(lambda x: \n",
    "        1 if pd.notna(x) and '(Əmlak sahibi)' in str(x) else \n",
    "        2 if pd.notna(x) and '(Vasitəçi)' in str(x) else 3)\n",
    "    df['SellerType'] = df['SellerType'].astype('Int64')\n",
    "\n",
    "\n",
    "    df['AreaInSot'] = pd.to_numeric(df['AreaInSot'].str.lower().str.replace('sot', '').str.replace(',', '.').str.strip(),errors='coerce')\n",
    "\n",
    "    #-----------------------------------------------------------------------\n",
    "    city_map = {\n",
    "        \"Ağcabədi\": 17, \"Ağdam\": 18, \"Ağdaş\": 19, \"Ağstafa\": 20, \"Ağsu\": 21,\n",
    "        \"Astara\": 22, \"Bakı\": 23, \"Balakən\": 24, \"Beyləqan\": 25, \"Bərdə\": 26,\n",
    "        \"Biləsuvar\": 27, \"Cəlilabad\": 28, \"Daşkəsən\": 29, \"Gədəbəy\": 30,\n",
    "        \"Gəncə\": 31, \"Göyçay\": 32, \"Göygöl\": 33, \"Hacıqabul\": 34, \"Xaçmaz\": 35,\n",
    "        \"Xankəndi\": 36, \"Xırdalan\": 37, \"Xızı\": 38, \"Xudat\": 39, \"İmişli\": 40,\n",
    "        \"İsmayıllı\": 41, \"Kürdəmir\": 42, \"Qax\": 43, \"Qazax\": 44, \"Qəbələ\": 45,\n",
    "        \"Qobustan\": 46, \"Quba\": 47, \"Qusar\": 48, \"Lerik\": 49, \"Lənkəran\": 50,\n",
    "        \"Masallı\": 51, \"Mingəçevir\": 52, \"Naxçıvan\": 53, \"Naxçıvan MR\": 54,\n",
    "        \"Neftçala\": 55, \"Oğuz\": 56, \"Saatlı\": 57, \"Sabirabad\": 58, \"Salyan\": 59,\n",
    "        \"Samux\": 60, \"Siyəzən\": 61, \"Sumqayıt\": 62, \"Şabran\": 63, \"Şamaxı\": 64,\n",
    "        \"Şəki\": 65, \"Şəmkir\": 66, \"Şirvan\": 67, \"Tərtər\": 68, \"Tovuz\": 69,\n",
    "        \"Ucar\": 70, \"Yardımlı\": 71, \"Yevlax\": 72, \"Zaqatala\": 73, \"Zərdab\": 74\n",
    "    }\n",
    "\n",
    "    metro_mapping = {\n",
    "        \"20 Yanvar\": 1, \"28 May\": 2, \"8 Noyabr\": 3, \"Avtovağzal\": 4, \"Azadlıq\": 5, \"Bakmil\": 6,\n",
    "        \"Dərnəgül\": 7, \"Elmlər Akademiyası\": 8, \"Əhmədli\": 9, \"Gənclik\": 10, \"Həzi Aslanov\": 11,\n",
    "        \"İçərişəhər\": 12, \"İnşaatçılar\": 13, \"Koroğlu\": 14, \"Memar Əcəmi\": 15, \"Nəriman Nərimanov\": 16,\n",
    "        \"Nəsimi\": 17, \"Neftçilər\": 18, \"Nizami\": 19, \"Qara Qarayev\": 20, \"Sahil\": 21,\n",
    "        \"Xətai\": 22, \"Xalqlar dostluğu\": 23, \"Xocaəsən\": 24, \"Ulduz\": 25, \"Cəfər Cabbarlı\": 26\n",
    "    }\n",
    "\n",
    "    settlement_mapping = {\n",
    "        \"Abşeron r.\": 1, \"Aşağı Güzdək\": 2, \"Atyalı\": 3, \"Ceyranbatan qəs.\": 4, \"Çiçək qəs.\": 5, \"Digah\": 6,\n",
    "        \"Fatmayi\": 7, \"Göradil\": 8, \"Hökməli\": 9, \"Köhnə Corat\": 10, \"Qobu\": 11, \"Masazır\": 12,\n",
    "        \"Mehdiabad\": 13, \"Məmmədli\": 14, \"Novxanı\": 15, \"Pereküşkül\": 16, \"Saray\": 17, \"Yeni Corat\": 18,\n",
    "        \"Zuğulba\": 19, \"Binəqədi r.\": 20, \"Alatava 2\": 21, \"28 May qəs.\": 22, \"6-cı mikrorayon\": 23,\n",
    "        \"7-ci mikrorayon\": 24, \"8-ci mikrorayon\": 25, \"9-cu mikrorayon\": 26, \"Biləcəri qəs.\": 27,\n",
    "        \"Binəqədi qəs.\": 28, \"Xocəsən\": 29, \"Xutor qəsəbəsi\": 30, \"Rəsulzadə qəs.\": 31, \"Sulutəpə qəs.\": 32,\n",
    "        \"Xətai r.\": 33, \"Ağ şəhər\": 34, \"Əhmədli\": 35, \"H.Aslanov qəs.\": 36, \"Köhnə Günəşli qəs.\": 37,\n",
    "        \"NZS\": 38, \"Xəzər r.\": 39, \"Binə qəs.\": 40, \"Buzovna\": 41, \"Dübəndi\": 42, \"Gürgən\": 43,\n",
    "        \"Qala\": 44, \"Mərdəkan\": 45, \"Şağan\": 46, \"Şimal qres\": 47, \"Şüvəlan\": 48, \"Türkan\": 49,\n",
    "        \"Zirə\": 50, \"Qaradağ qəs.\": 51, \"Ələt\": 52, \"Baş ələt\": 52, \"Qızıldaş qəs.\": 53, \"Qobustan qəs.\": 54, \"Lökbatan qəs.\": 55,\n",
    "        \"Müşfiqabad qəs.\": 56, \"Puta qəs.\": 57, \"Sahil qəs.\": 58, \"Səngəçal qəs.\": 59, \"Şubani qəs.\": 60, \"Nərimanov r.\": 61,\n",
    "        \"Böyükşor qəs.\": 62, \"Nəsimi r.\": 63, \"1-ci mikrorayon\": 64, \"2-ci mikrorayon\": 65, \"3-cü mikrorayon\": 66,\n",
    "        \"4-cü mikrorayon\": 67, \"5-ci mikrorayon\": 68, \"Kubinka\": 69, \"Nizami r.\": 70, \"8-ci kilometr\": 71,\n",
    "        \"Keşlə qəs.\": 72, \"Pirallahı\": 73, \"Sabunçu r.\": 74, \"Albalılıq\": 75, \"Bakıxanov qəs.\": 76,\n",
    "        \"Balaxanı qəs.\": 77, \"Bilgəh qəs.\": 78, \"Kürdəxanı qəs.\": 79, \"Maştağa qəs.\": 80, \"Nardaran qəs.\": 81, \"Pirşağı qəs.\": 82,\n",
    "        \"Ramana qəs.\": 83, \"Sabunçu qəs.\": 84, \"Savalan qəs.\": 85, \"Yeni Balaxanı\": 86, \"Yeni Ramana\": 87, \"Zabrat qəs.\": 88,\n",
    "        \"Səbail r.\": 89, \"20-ci sahə\": 90, \"Badamdar qəs.\": 91, \"Bayıl qəs.\": 92, \"Bibi Heybət qəs.\": 93, \"Şıxov\": 94,\n",
    "        \"Suraxanı r.\": 95, \"Bahar qəs.\": 96, \"Bülbülə qəs.\": 97, \"Dədə Qorqud qəs.\": 98, \"Əmircan qəs.\": 99, \"Günəşli\": 100,\n",
    "        \"Hövsan qəs.\": 101, \"Qaraçuxur\": 102, \"Massiv A\": 103, \"Massiv B\": 104, \"Massiv D\": 105,\n",
    "        \"Massiv G\": 106, \"Massiv V\": 107, \"Suraxanı qəs.\": 108, \"Şərq\": 109, \"Yeni Günəşli qəs.\": 110,\n",
    "        \"Yeni Suraxanı qəs.\": 111, \"Zığ qəs.\": 112, \"Yasamal r.\": 113, \"Yasamal qəs.\": 114, \"Yeni Yasamal qəs.\": 115, \"Kimya şəhərciyi\": 117, \"Məhəmmədli\": 119, \n",
    "        \"Papanin\": 122, \"Qara şəhər\": 123, \"Ümid\": 125, \"Zaqulba\": 128, \"Alatava\": 130, \"Albalılıq\": 131, \n",
    "        \"Güzdək\": 132, \"Ceyildağ qəs.\": 133, \"Heybət qəs.\": 134, \"Qarakosa qəs.\": 135, \"Qurd Qapısı\": 136 , \n",
    "        \"Çilov qəs.\": 137, \"Şamaxinka\": 138, \"Şıxlar qəs.\": 139, \"Şonqar qəs.\": 140, \"Xocəsən qəs.\": 141, \n",
    "        \"Korgöz qəs.\": 142, \"Kotal qəs.\": 143, \"UPD\": 144, \"Yeni Ələt qəs.\": 145, \"kənd Əhmədli\": 146}\n",
    "\n",
    "    def extract_city_name(listing_name):\n",
    "        listing = str(listing_name).lower()\n",
    "        cities_sorted = sorted(city_map.keys(), key=len, reverse=True)\n",
    "\n",
    "        for city in cities_sorted:\n",
    "            if city.lower() in listing:\n",
    "                return city\n",
    "        return None\n",
    "\n",
    "    def extract_metro_name(listing_name):\n",
    "        listing = str(listing_name).lower()\n",
    "\n",
    "        for metro_name in metro_mapping:\n",
    "            metro_patterns = [\n",
    "                f\"{metro_name.lower()} metrosu\",\n",
    "                f\"{metro_name.lower()} metro\",\n",
    "                f\"{metro_name.lower()},\"\n",
    "            ]\n",
    "            for pattern in metro_patterns:\n",
    "                if pattern in listing:\n",
    "                    return metro_name\n",
    "            if metro_name.lower() in listing:\n",
    "                return metro_name\n",
    "        return None\n",
    "\n",
    "    def extract_settlement_name(listing_name):\n",
    "        listing = str(listing_name).lower()\n",
    "        settlements_sorted = sorted(settlement_mapping.keys(), key=len, reverse=True)\n",
    "\n",
    "        # Əvvəlcə qəsəbə axtar\n",
    "        for settlement_name in settlements_sorted:\n",
    "            if \"qəs\" in settlement_name.lower() or \"mikrorayon\" in settlement_name.lower() or \"massiv\" in settlement_name.lower():\n",
    "                if settlement_name.lower() in listing:\n",
    "                    return settlement_name\n",
    "\n",
    "        # Sonra rayon axtar\n",
    "        for settlement_name in settlements_sorted:\n",
    "            if \" r.\" in settlement_name:\n",
    "                rayon_name = settlement_name.replace(\" r.\", \"\").lower()\n",
    "                if f\"{rayon_name} rayonu\" in listing or f\"{rayon_name} r.\" in listing:\n",
    "                    return settlement_name\n",
    "        return None\n",
    "\n",
    "    # ------------------- DataFrame tətbiqi -------------------\n",
    "\n",
    "    # df sənin məlumat DataFrame-indir\n",
    "    df['CityName'] = df['ListingName'].apply(extract_city_name)\n",
    "    df['MetroName'] = df['ListingName'].apply(extract_metro_name)\n",
    "    df['SettlementName'] = df['ListingName'].apply(extract_settlement_name)\n",
    "\n",
    "    # ID-ləri map et\n",
    "    df['CityID'] = df['CityName'].map(city_map).fillna(23).astype(int)  # default: Bakı\n",
    "    df['MetroID'] = df['MetroName'].map(metro_mapping).astype('Int64')  # nullable\n",
    "    df['SettlementsID'] = df['SettlementName'].map(settlement_mapping).astype('Int64')\n",
    "\n",
    "    # Lazımsız kolonları sil\n",
    "    df.drop(['CityName', 'MetroName', 'SettlementName'], axis=1, inplace=True)\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "\n",
    "    df['Currency'] = 'AZN'\n",
    "\n",
    "\n",
    "    # 12. Latitude və Longitude null olan sətirləri silmək\n",
    "    df = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "    # Index-i sıfırlamaq\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def cleaner():\n",
    "    while True:\n",
    "        raw = raw_data.get()        \n",
    "        cleaned = preprocess(raw)        \n",
    "        cleaned_data.put(cleaned)       \n",
    "        raw_data.task_done()\n",
    "\n",
    "\n",
    "\n",
    "def inserter():\n",
    "    while True:\n",
    "        cleaned = cleaned_data.get()\n",
    "        insert_data(cleaned)\n",
    "        cleaned_data.task_done()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def insert_data(df):    \n",
    "    # Database bağlantısı\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "            \"SERVER=DESKTOP-KIDL0VQ\\\\SQLEXPRESS;\" \n",
    "            \"DATABASE=RealEstateDB;\"\n",
    "            \"Trusted_Connection=yes;\")\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Database Connection\")\n",
    "    except Exception as e:\n",
    "        print(f\"Database Connect Xeta: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Orijinal məlumat sayı: {len(df)}\")\n",
    "    df = df.drop_duplicates(subset=['ListingID'])\n",
    "    print(f\"Dublikatlar silindikdən sonra: {len(df)}\")\n",
    "\n",
    "    # null deyerleri ucun\n",
    "    def safe_value(value):\n",
    "        if pd.isna(value):\n",
    "            return None\n",
    "        return value\n",
    "\n",
    "    # datalar database-de yoxlanir\n",
    "    def is_listing_exists(listing_id, table_name):\n",
    "        try:\n",
    "            query = f\"SELECT COUNT(*) FROM Dynamic.{table_name} WHERE ListingID = ?\"\n",
    "            cursor.execute(query, (listing_id,))\n",
    "            result = cursor.fetchone()\n",
    "            return result[0] > 0\n",
    "        except Exception as e:\n",
    "            print(f\"Yoxlama xətası {table_name} - {listing_id}: {e}\")\n",
    "            return False\n",
    "\n",
    "    stats = {\n",
    "        'apartment': 0,\n",
    "        'house': 0,\n",
    "        'office': 0,\n",
    "        'garage': 0,\n",
    "        'land': 0,\n",
    "        'commercial': 0,\n",
    "        'estate_listing': 0,\n",
    "        'seller_info': 0,\n",
    "        'url': 0,\n",
    "        'labels': 0,\n",
    "        'description': 0,\n",
    "        'listing_images': 0 }\n",
    "\n",
    "    try:        \n",
    "        estate_query = \"\"\"\n",
    "        INSERT INTO Dynamic.EstateListing (ListingID, ListingName, SalesType, DailyRent, CategoryID, SellerType, Price, PricePerSqm, Currency, CityID, Address, Date, Time, MetroID, SettlementsID, Latitude, Longitude)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            \n",
    "            if not is_listing_exists(listing_id, \"EstateListing\"):\n",
    "                try:\n",
    "                    cursor.execute(estate_query, (listing_id,\n",
    "                        safe_value(row.get(\"ListingName\")),\n",
    "                        safe_value(row.get(\"SalesType\")),\n",
    "                        safe_value(row.get(\"DailyRent\")),\n",
    "                        safe_value(row.get(\"CategoryID\")),\n",
    "                        safe_value(row.get(\"SellerType\")),\n",
    "                        safe_value(row.get(\"Price\")),\n",
    "                        safe_value(row.get(\"PricePerSqm\")),\n",
    "                        safe_value(row.get(\"Currency\")),\n",
    "                        safe_value(row.get(\"CityID\")),\n",
    "                        safe_value(row.get(\"Address\")),\n",
    "                        safe_value(row.get(\"Date\")),\n",
    "                        safe_value(row.get(\"Time\")),\n",
    "                        safe_value(row.get(\"MetroID\")),\n",
    "                        safe_value(row.get(\"SettlementsID\")),\n",
    "                        safe_value(row.get(\"Latitude\")),\n",
    "                        safe_value(row.get(\"Longitude\"))))\n",
    "                    stats['estate_listing'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\" X EstateListing {listing_id} xətası: {e}\")\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        seller_query = \"\"\"\n",
    "        INSERT INTO Dynamic.SellerInfo (ListingID, ListingName, Contact, SellerType, Agency, Residence)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"SellerInfo\"):\n",
    "                try:\n",
    "                    cursor.execute(seller_query, (\n",
    "                        listing_id,\n",
    "                        safe_value(row.get(\"ListingName\")),\n",
    "                        safe_value(row.get(\"Contact\")),\n",
    "                        safe_value(row.get(\"SellerType\")),\n",
    "                        safe_value(row.get(\"Agency\")),\n",
    "                        safe_value(row.get(\"Residence\"))\n",
    "                    ))\n",
    "                    stats['seller_info'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ SellerInfo {listing_id} xətası: {e}\")\n",
    "\n",
    "        description_query = \"\"\"\n",
    "        INSERT INTO Dynamic.Description (ListingID, Description)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Description\"):\n",
    "                try:\n",
    "                    cursor.execute(description_query, (\n",
    "                        listing_id,\n",
    "                        safe_value(row.get(\"Description\"))\n",
    "                    ))\n",
    "                    stats['description'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Description {listing_id} xətası: {e}\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        if df[\"CategoryID\"].isin([1, 2, 3]).any():\n",
    "            apartment_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Apartment (ListingID, CategoryID, FloorNumber, TotalFloors, FieldAreaSqm, CountRoom, Title, Mortgage, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_apartments = df[df[\"CategoryID\"].isin([1, 2, 3])]\n",
    "            \n",
    "            for index, row in df_apartments.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Apartment\"):\n",
    "                    try:\n",
    "                        cursor.execute(apartment_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FloorNumber\")),\n",
    "                            safe_value(row.get(\"TotalFloors\")),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"CountRoom\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Mortgage\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['apartment'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\" X Apartment {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 4).any():\n",
    "            house_query = \"\"\"\n",
    "            INSERT INTO Dynamic.House (ListingID, CategoryID, FieldAreaSqm, AreaInSot, CountRoom, Mortgage, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_house = df[df[\"CategoryID\"] == 4]\n",
    "            \n",
    "            for index, row in df_house.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"House\"):\n",
    "                    try:\n",
    "                        cursor.execute(house_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"AreaInSot\")),\n",
    "                            safe_value(row.get(\"CountRoom\")),\n",
    "                            safe_value(row.get(\"Mortgage\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['house'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"X House {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 5).any():\n",
    "            office_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Office (ListingID, CategoryID, FieldAreaSqm, [BuildingType (ForOffice)], CountRoom, Title, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_office = df[df[\"CategoryID\"] == 5]\n",
    "            \n",
    "            for index, row in df_office.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Office\"):\n",
    "                    try:\n",
    "                        cursor.execute(office_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"BuildingType (ForOffice)\")),\n",
    "                            safe_value(row.get(\"CountRoom\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['office'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\" X Office {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 6).any():\n",
    "            garage_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Garage (ListingID, CategoryID, FieldAreaSqm, Title)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_garage = df[df[\"CategoryID\"] == 6]\n",
    "            \n",
    "            for index, row in df_garage.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Garage\"):\n",
    "                    try:\n",
    "                        cursor.execute(garage_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"Title\"))))\n",
    "                        stats['garage'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\" X Garage {listing_id} xətası: {e}\")\n",
    "\n",
    "\n",
    "        if (df[\"CategoryID\"] == 7).any():\n",
    "            land_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Land (ListingID, CategoryID, FieldAreaSqm, Title, Mortgage)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_land = df[df[\"CategoryID\"] == 7]\n",
    "            \n",
    "            for index, row in df_land.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Land\"):\n",
    "                    try:\n",
    "                        cursor.execute(land_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Mortgage\")))) \n",
    "                        stats['land'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"X Land {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 8).any():\n",
    "            commercial_query = \"\"\"\n",
    "            INSERT INTO Dynamic.CommercialProperty (ListingID, CategoryID, FieldAreaSqm, Title, Mortgage, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_commercial = df[df[\"CategoryID\"] == 8]\n",
    "            \n",
    "            for index, row in df_commercial.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"CommercialProperty\"):\n",
    "                    try:\n",
    "                        cursor.execute(commercial_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Mortgage\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['commercial'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"X Commercial Property {listing_id} xətası: {e}\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        # URL\n",
    "        url_query = \"\"\"\n",
    "        INSERT INTO Dynamic.URL (ListingID, URL)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"URL\"):\n",
    "                try:\n",
    "                    cursor.execute(url_query, (\n",
    "                        listing_id,\n",
    "                        safe_value(row.get(\"URL\"))\n",
    "                    ))\n",
    "                    stats['url'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\" X URL {listing_id} xətası: {e}\")\n",
    "\n",
    "\n",
    "        labels_query = \"\"\"\n",
    "        INSERT INTO Dynamic.Labels (ListingID, Labels)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "\n",
    "        def is_listing_label_exists(listing_id, label):\n",
    "            check_query = \"SELECT 1 FROM Dynamic.Labels WHERE ListingID = ? AND Labels = ?\"\n",
    "            cursor.execute(check_query, (listing_id, label))\n",
    "            return cursor.fetchone() is not None\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\"):\n",
    "                labels_raw = row.get(\"Labels\", \"\")\n",
    "                \n",
    "                labels_list = []\n",
    "                if labels_raw:\n",
    "                    if isinstance(labels_raw, str):\n",
    "                        clean_str = str(labels_raw).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "                        labels_list = [x.strip() for x in clean_str.split(\",\") if x.strip()]\n",
    "                    elif isinstance(labels_raw, list):\n",
    "                        labels_list = [str(x).strip() for x in labels_raw if str(x).strip()]\n",
    "                \n",
    "                for label in labels_list:\n",
    "                    if not is_listing_label_exists(listing_id, label):\n",
    "                        try:\n",
    "                            cursor.execute(labels_query, (listing_id, label))\n",
    "                            stats['labels'] += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\" X Labels {listing_id} ({label}) xətası: {e}\")\n",
    "\n",
    "\n",
    "        def is_image_exists(image_url):\n",
    "            try:\n",
    "                check_query = \"SELECT COUNT(*) FROM Dynamic.ListingImages WHERE ImageURL = ?\"\n",
    "                cursor.execute(check_query, (image_url,))\n",
    "                result = cursor.fetchone()\n",
    "                return result[0] > 0\n",
    "            except Exception as e:\n",
    "                print(f\"Image yoxlama xətası: {e}\")\n",
    "                return False\n",
    "\n",
    "        listing_images_query = \"\"\"\n",
    "        INSERT INTO Dynamic.ListingImages (ListingID, ImageURL)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "\n",
    "        processed_images = set()\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\"):\n",
    "                image_links = row.get(\"Images\")\n",
    "                \n",
    "                if image_links and listing_id:\n",
    "                    if isinstance(image_links, str):\n",
    "                        try:\n",
    "                            import json\n",
    "                            image_list = json.loads(image_links)\n",
    "                        except:\n",
    "                            image_list = [link.strip() for link in image_links.split(',') if link.strip()]\n",
    "                    elif isinstance(image_links, list):\n",
    "                        image_list = image_links\n",
    "                    else:\n",
    "                        image_list = []\n",
    "                    \n",
    "                    for image_url in image_list:\n",
    "                        image_url_clean = safe_value(image_url)\n",
    "                        \n",
    "                        if image_url_clean and image_url_clean not in processed_images:\n",
    "                            if not is_image_exists(image_url_clean):\n",
    "                                try:\n",
    "                                    cursor.execute(listing_images_query, (\n",
    "                                        listing_id,\n",
    "                                        image_url_clean\n",
    "                                    ))\n",
    "                                    stats['listing_images'] += 1\n",
    "                                    processed_images.add(image_url_clean)\n",
    "                                except Exception as e:\n",
    "                                    print(f\"X Image {listing_id} xətası: {e}\")\n",
    "\n",
    "        # Final commit\n",
    "        conn.commit()\n",
    "        print(\"Uğurlu\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ümumi xəta baş verdi: {e}\")\n",
    "        try:\n",
    "            conn.rollback()\n",
    "            print(\"Rollback edildi\")\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"Database bağlantısı bağlandı\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Nəticələr\n",
    "    print(f\"   EstateListing: {stats['estate_listing']}\")\n",
    "    print(f\"   SellerInfo:    {stats['seller_info']}\")\n",
    "    print(f\"   Description:   {stats['description']}\")\n",
    "    print(f\"   Apartment:     {stats['apartment']}\")\n",
    "    print(f\"   House:         {stats['house']}\")\n",
    "    print(f\"   Office:        {stats['office']}\")\n",
    "    print(f\"   Garage:        {stats['garage']}\")\n",
    "    print(f\"   Land:          {stats['land']}\")\n",
    "    print(f\"   Commercial:    {stats['commercial']}\")\n",
    "    print(f\"   URL:           {stats['url']}\")\n",
    "    print(f\"   Labels:        {stats['labels']}\")\n",
    "    print(f\"   Images:        {stats['listing_images']}\")\n",
    "    print(f\"   TOPLAM:        {sum(stats.values())}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Thread(target=scrap, daemon=True).start()\n",
    "    Thread(target=cleaner, daemon=True).start()\n",
    "    Thread(target=inserter, daemon=True).start()\n",
    "\n",
    "    # Prosesi aciq saxlamaq ucun\n",
    "    raw_data.join()\n",
    "    cleaned_data.join()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
