{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup                                       # HTML və XML-dən məlumat çıxarmaq üçün\n",
    "from selenium import webdriver                                      # Brauzeri avtomatik idarə etmək üçün\n",
    "from selenium.webdriver.chrome.service import Service               # ChromeDriver-i başlatmaq üçün\n",
    "from selenium.webdriver.common.by import By                         # HTML elementlərini axtarmaq üçün (məs: By.CLASS_NAME)\n",
    "from webdriver_manager.chrome import ChromeDriverManager            # ChromeDriver versiyasını avtomatik endirmək üçün\n",
    "from selenium.webdriver.chrome.options import Options               # Chrome brauzerinə xüsusi ayarlar vermək üçün\n",
    "from selenium.webdriver.support.ui import WebDriverWait             # Elementlərin yüklənməsini gözləmək üçün\n",
    "from selenium.webdriver.support import expected_conditions as EC    # Müəyyən şərtlər ödənənə qədər gözləmək üçün\n",
    "from selenium.common.exceptions import TimeoutException             # Vaxt aşımı xətasını idarə etmək üçün\n",
    "from selenium.webdriver.common.keys import Keys                     # Klaviatura düymələrini simulyasiya etmək üçün (məs: ENTER)\n",
    "import time                                                         # Kodda gecikmə vermək üçün (məs: time.sleep)\n",
    "import pandas as pd                                                 # Verilənlərlə işləmək üçün (DataFrame, CSV və s.)\n",
    "import re                                                           # Mətn təmizləmək, regex (müntəzəm ifadələr) ilə işləmək üçün\n",
    "import pyodbc                                                       # SQL Server (və digər ODBC dəstəkləyən verilənlər bazaları) ilə bağlantı qurmaq üçün\n",
    "from sqlalchemy import create_engine                                # SQLAlchemy ilə verilənlər bazasına bağlantı yaratmaq və pandas ilə işləmək üçün\n",
    "import requests\n",
    "import os\n",
    "import base64\n",
    "import numpy as np\n",
    "import json\n",
    "import queue\n",
    "from threading import Thread\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import undetected_chromedriver as uc\n",
    "import random\n",
    "import threading\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "raw_data = queue.Queue()\n",
    "cleaned_data = queue.Queue()\n",
    "list_data = []\n",
    "\n",
    "# Global seen_links set - bütün thread-lər arasında paylaşılan\n",
    "global_seen_links = set()\n",
    "# Thread-safe əməliyyatlar üçün lock\n",
    "seen_links_lock = threading.Lock()\n",
    "\n",
    "def scrap():\n",
    "    base_urls = [\n",
    "        # \"https://bina.az/alqi-satqi\",\n",
    "        # \"https://bina.az/kiraye\",\n",
    "        # \"https://bina.az/kiraye?paid_daily=true\",\n",
    "        \n",
    "        \n",
    "        \"https://bina.az/baki/alqi-satqi/menziller\",\n",
    "        \"https://bina.az/baki/alqi-satqi/heyet-evleri\",\n",
    "        \"https://bina.az/baki/alqi-satqi/ofisler\",\n",
    "        \"https://bina.az/baki/alqi-satqi/qarajlar\",\n",
    "        \"https://bina.az/baki/alqi-satqi/torpaq\",\n",
    "        \"https://bina.az/baki/alqi-satqi/obyektler\",\n",
    "        \"https://bina.az/baki/kiraye/menziller\",\n",
    "        \"https://bina.az/baki/kiraye/heyet-evleri\",\n",
    "        \"https://bina.az/baki/kiraye/ofisler\",\n",
    "        \"https://bina.az/baki/kiraye/qarajlar\",\n",
    "        \"https://bina.az/baki/kiraye/torpaq\",\n",
    "        \"https://bina.az/baki/kiraye/obyektler\"]\n",
    "\n",
    "    def scrape_url(current_url):\n",
    "        options = uc.ChromeOptions()\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        # options.add_argument(\"--start-maximized\")\n",
    "\n",
    "        driver = uc.Chrome(version_main=137, options=options, headless=False)\n",
    "        # driver.maximize_window()\n",
    "\n",
    "        print(f\"[Start] {current_url}\")\n",
    "        i = 1\n",
    "        while True:\n",
    "            if \"paid_daily=true\" in current_url:\n",
    "                page_url = f\"https://bina.az/kiraye?page={i}&paid_daily=true\"\n",
    "            else:\n",
    "                page_url = f\"{current_url}?page={i}\"\n",
    "\n",
    "            try:\n",
    "                driver.get(page_url)\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR,\"#search-page-regular-items a[href^='/item']\")))\n",
    "            except TimeoutException:\n",
    "                print(f\"Xəta: səhifə yüklənmədi → {page_url}\")\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            for _ in range(i * 30):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, \"#search-page-regular-items a[href^='/item']\")\n",
    "            all_links = [e.get_attribute(\"href\") for e in elements if e.get_attribute(\"href\")]\n",
    "            \n",
    "            # Thread-safe şəkildə yeni linkləri ayırmaq\n",
    "            new_links = []\n",
    "            with seen_links_lock:\n",
    "                for l in all_links:\n",
    "                    if l not in global_seen_links:\n",
    "                        global_seen_links.add(l)\n",
    "                        new_links.append(l)\n",
    "\n",
    "\n",
    "            for link in new_links:\n",
    "                try:\n",
    "                    driver.get(link)\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"h1\")))\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    data = {\"URL\": link}\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Elan ID\n",
    "                    ann_id = soup.find(\"div\", {\"class\": \"product-actions__id\"})\n",
    "                    data[\"ListingID\"] = ann_id.text.strip() if ann_id else None\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Elan adi\n",
    "                    announce = soup.find(\"h1\", {\"class\":\"product-title\"})\n",
    "                    data[\"ListingName\"] = announce.text.strip() if announce else None\n",
    "\n",
    "                    #--------------------------------------------------------------------------        \n",
    "                    # Əmlak tipini tapmaq üçün breadcrumb-dan istifadə edirik\n",
    "                    type_block = soup.find_all(\"a\", {\"class\":\"product-breadcrumbs__i-link\"})\n",
    "                    if len(type_block) >= 2:\n",
    "                        data['SalesType'] = type_block[0].text.strip()  \n",
    "                    else:\n",
    "                        data['SalesType'] = None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # ayliq gunluk kiraye\n",
    "                    daily_rent = soup.find(\"span\", {\"class\":\"price-per\"})\n",
    "                    data['DailyRent'] = daily_rent.text.strip() if daily_rent else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Tarix \n",
    "                    date = soup.find_all(\"span\", {\"class\":\"product-statistics__i-text\"})\n",
    "                    if len(date) >= 2:\n",
    "                        data[\"ListingDate\"] = date[1].text.strip()\n",
    "                    else:\n",
    "                        data[\"ListingDate\"] = None\n",
    "                    \n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # melumat blokunda olan datalar ucun (Kategoriya, Mertebe , otaq sayi vs.)\n",
    "                    # melumatlari saxlamaq ucun dictionary (key-value)\n",
    "                    data[\"CategoryID\"] = None\n",
    "                    data[\"Floor\"] = None\n",
    "                    data[\"FieldAreaSqm\"] = None\n",
    "                    data[\"CountRoom\"] = None\n",
    "                    data[\"Title\"] = None\n",
    "                    data[\"Mortgage\"] = None\n",
    "                    data[\"Repaired\"] = None\n",
    "                    data[\"BuildingType (ForOffice)\"] = None\n",
    "                    data[\"AreaInSot\"] = None\n",
    "\n",
    "                    # melumat bloklarini tapmaq\n",
    "                    info_blok = soup.find_all(\"div\", {\"class\":\"product-properties__i\"})\n",
    "\n",
    "                    # FƏRQLİ ADLARIN QARŞILIĞINI SAXLAYIRIQ\n",
    "                    label_mapping = {\n",
    "                        \"Kateqoriya\": \"CategoryID\",\n",
    "                        \"Mərtəbə\": \"Floor\",\n",
    "                        \"Sahə\": \"FieldAreaSqm\",\n",
    "                        \"Otaq sayı\": \"CountRoom\",\n",
    "                        \"Çıxarış\": \"Title\",\n",
    "                        \"İpoteka\": \"Mortgage\",\n",
    "                        \"Təmir\": \"Repaired\",\n",
    "                        \"Binanın növü\": \"BuildingType (ForOffice)\",\n",
    "                        \"Torpaq sahəsi\": \"AreaInSot\"}\n",
    "\n",
    "\n",
    "                    # her blokda basliq ve ona uygun deyerin tapilmasi\n",
    "                    for block in info_blok:\n",
    "                        # label_tag basliqlarin oldugu kod , span_tag deyerlerin oldugu kod\n",
    "                        label_tag = block.find(\"label\", {\"class\":\"product-properties__i-name\"})\n",
    "                        span_tag = block.find(\"span\", {\"class\":\"product-properties__i-value\"})\n",
    "                        \n",
    "                        # Əgər həm başlıq, həm də dəyər varsa:\n",
    "                        if label_tag and span_tag:\n",
    "                            label = label_tag.text.strip()  # Məs: \"Kateqoriya\"\n",
    "                            value = span_tag.text.strip()  # Məs: \"Köhne tikili\"\n",
    "                            \n",
    "                            # # Debug üçün - hansı etiketlərin olduğunu görmək üçün\n",
    "                            # print(f\"Tapılan etiket: '{label}' - '{value}'\")\n",
    "                            \n",
    "                            # Etiketləri uyğunlaşdırırıq\n",
    "                            if label in label_mapping:\n",
    "                                data[label_mapping[label]] = value\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Qiymət\n",
    "                    price = soup.find(\"span\", {\"class\": \"price-val\"})\n",
    "                    data[\"Price\"] = price.text.strip() if price else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # 1 kv.m üçün qiymet\n",
    "                    kv = soup.find_all(\"div\", {\"class\":\"product-price__i\"})\n",
    "                    if len(kv) >= 2:\n",
    "                        data[\"PricePerSqm\"] = kv[1].text.strip()\n",
    "                    else:\n",
    "                        data[\"PricePerSqm\"] = None\n",
    "\n",
    "                    \n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Valyuta\n",
    "                    currecy = soup.find(\"span\", {\"class\":\"price-cur\"})\n",
    "                    data[\"Currency\"] = currecy.text.strip() if currecy else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Unvan\n",
    "                    address = soup.find(\"div\", {\"class\":\"product-map__left__address\"})\n",
    "                    data[\"Address\"] = address.text.strip() if address else None\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Yerləşdiyi ərazi\n",
    "                    location = soup.find(\"div\", {\"class\":\"location\"})\n",
    "                    data['CityID'] = location.text.strip() if location else None\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Satici (Şəxs)\n",
    "                    owner = soup.find(\"div\", {\"class\":\"product-owner__info-name\"})\n",
    "                    data[\"SalesPerson\"] = owner.text.strip() if owner else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Satici novu\n",
    "                    owner_type = soup.find(\"div\", {\"class\":\"product-owner__info-region\"})\n",
    "                    owner_type_2 = soup.find(\"div\", {\"class\":\"product-owner__residence-info-region\"})\n",
    "\n",
    "                    if owner_type:\n",
    "                        data['SellerType'] = owner_type.text.strip()\n",
    "                    elif owner_type_2:\n",
    "                        data['SellerType'] = owner_type_2.text.strip()\n",
    "                    else:\n",
    "                        data['SellerType'] = None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Agentlik \n",
    "                    agent = soup.find(\"div\", {\"class\":\"product-shop__owner-name\"})\n",
    "                    data[\"Agency\"] = agent.text.strip() if agent else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Residence Adı\n",
    "                    residence = soup.find(\"div\", {\"class\":\"product-owner__residence-info-name\"})\n",
    "                    data[\"Residence\"] = residence.text.strip() if residence else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # elaqe nomresi\n",
    "                    contact = soup.find(\"div\", {\"class\":\"product-phones__btn-value\"})\n",
    "                    data[\"Contact\"] = contact.text.strip() if contact else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Etiket\n",
    "                    labels = soup.find(\"ul\", class_=\"product-extras bz-d-flex bz-align-center bz-gap-15 bz-wrap-wrap\")\n",
    "                    data[\"Labels\"] = [i.get_text(strip=True) for i in labels.find_all(\"li\")] if labels else []\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Açıqlama\n",
    "                    description = soup.find(\"div\", {\"class\":\"product-description__content\"})\n",
    "                    data[\"Description\"] = description.text.strip() if description else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # Koordinatlar\n",
    "                    coordinates = soup.find(\"div\", {\"id\": \"item_map\"})\n",
    "                    data[\"Latitude\"] = coordinates.get(\"data-lat\") if coordinates else None\n",
    "                    data[\"Longitude\"] = coordinates.get(\"data-lng\") if coordinates else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # sekil linkleri \n",
    "                    slides = soup.find_all('div', class_='product-photos__slider-top-i')\n",
    "                    image_links = []\n",
    "\n",
    "                    for slide in slides:\n",
    "                        # background-image'dən link\n",
    "                        span = slide.find('span', class_='product-photos__slider-top-i_background')\n",
    "                        if span and 'style' in span.attrs:\n",
    "                            style = span['style']\n",
    "                            start = style.find(\"url('\") + 5\n",
    "                            end = style.find(\"')\", start)\n",
    "                            url = style[start:end]\n",
    "                            if url:\n",
    "                                image_links.append(url)\n",
    "\n",
    "                        # img src-dən link (əgər varsa və təkrarlanmırsa)\n",
    "                        img = slide.find('img')\n",
    "                        if img and img.get('src') and img['src'] not in image_links:\n",
    "                            image_links.append(img['src'])\n",
    "\n",
    "                    data[\"Images\"] = image_links if image_links else None\n",
    "\n",
    "\n",
    "                    #--------------------------------------------------------------------------\n",
    "                    # # Fotolar\n",
    "                    # ann_id_div = soup.find('div', class_='product-actions__id')\n",
    "                    # ann_id = ann_id_div.text.strip().split(':')[-1].strip()\n",
    "\n",
    "                    # # Qovluq yaradılır\n",
    "                    # image_dir = f'sekiller/{ann_id}'\n",
    "                    # os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "                    # # Sadəcə kompüterdə şəkil kimi açılan formatlara icazə verilir\n",
    "                    # sekil_formatlari = ['jpg', 'jpeg', 'png', 'webp']\n",
    "\n",
    "                    # # Şəkilləri tap\n",
    "                    # sekiller = soup.find_all('img')\n",
    "                    # count = 1\n",
    "\n",
    "                    # for img in sekiller:\n",
    "                    #     src = img.get('src')\n",
    "                    #     if not src:\n",
    "                    #         continue\n",
    "\n",
    "                    #     try:\n",
    "                    #         if src.startswith('data:image'):\n",
    "                    #             # Base64 formatında şəkil\n",
    "                    #             header, encoded = src.split(',', 1)\n",
    "                    #             ext = header.split('/')[1].split(';')[0].lower()\n",
    "\n",
    "                    #             if ext not in sekil_formatlari:\n",
    "                    #                 continue\n",
    "\n",
    "                    #             image_data = base64.b64decode(encoded)\n",
    "                    #         else:\n",
    "                    #             # Normal linkli şəkil\n",
    "                    #             ext = src.split('.')[-1].split('?')[0].lower()\n",
    "\n",
    "                    #             if ext not in sekil_formatlari:\n",
    "                    #                 continue\n",
    "\n",
    "                    #             response = requests.get(src)\n",
    "                    #             image_data = response.content\n",
    "\n",
    "                    #         # Fayl adını .jpg kimi saxlayırıq (formatdan asılı olmayaraq)\n",
    "                    #         image_path = os.path.join(image_dir, f'{ann_id}_{count}.jpg')\n",
    "                    #         with open(image_path, 'wb') as f:\n",
    "                    #             f.write(image_data)\n",
    "\n",
    "                    #         # print(f'Şəkil saxlandı: {image_path}')\n",
    "                    #         count += 1\n",
    "\n",
    "                    #     except Exception as e:\n",
    "                    #         print(f'X Şəkil saxlanmadı: {src}, səbəb: {e}')\n",
    "\n",
    "\n",
    "\n",
    "                    list_data.append(data)\n",
    "                    raw_data.put(pd.DataFrame([data]))\n",
    "                    print(f\"total: {len(list_data)})\")\n",
    "\n",
    "                except TimeoutException:\n",
    "                    print(f\"[Timeout] scrape edilə bilmədi → {link}\")\n",
    "\n",
    "            i += 1  \n",
    "        \n",
    "        # driver.quit() \n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=len(base_urls)) as executor:\n",
    "        executor.map(scrape_url, base_urls)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Cleaning\n",
    "\n",
    "def preprocess(raw):\n",
    "    df = raw.copy()\n",
    "\n",
    "    # ListingID - integer tipinə çevrilmə\n",
    "    # df['ListingID'] = df['ListingID'].astype(str).str.replace('Elanın nömrəsi:', '', regex=True)\n",
    "    # df['ListingID'] = pd.to_numeric(df['ListingID'], errors='coerce')\n",
    "    # df['ListingID'] = df['ListingID'].astype(\"Int64\")  \n",
    "\n",
    "    df['ListingID'] = df['ListingID'].astype(str).str.replace('Elanın nömrəsi:', '', regex=True)\n",
    "    df['ListingID'] = pd.to_numeric(df['ListingID'], errors='coerce')\n",
    "    df['ListingID'] = df['ListingID'].apply(lambda x: '101' + str(int(x)) if pd.notna(x) else x)\n",
    "    df['ListingID'] = pd.to_numeric(df['ListingID'], errors='coerce').astype(\"Int64\")\n",
    "\n",
    "\n",
    "    # ListingName - string tipinə çevrilmə\n",
    "    df['ListingName'] = df['ListingName'].astype(\"string\")\n",
    "\n",
    "    # Boolean tiplər\n",
    "    df[['Title', 'Mortgage', 'Repaired']] = df[['Title', 'Mortgage', 'Repaired']].astype(bool)\n",
    "\n",
    "    # SellerType - kategorik dəyərləri integer-ə çevirmə\n",
    "    df['SellerType'] = df['SellerType'].replace({\"Yaşayış kompleksi\": 3, \"vasitəçi (agent)\": 2, \"mülkiyyətçi\": 1})\n",
    "    df['SellerType'] = pd.to_numeric(df['SellerType'], errors='coerce')\n",
    "    df['SellerType'] = df['SellerType'].astype(\"Int64\")  \n",
    "\n",
    "    # Contact - string tipinə çevrilmə və əvəzləmə\n",
    "    df['Contact'] = df['Contact'].astype(\"string\").str.replace(\"●●\", \"XX\")\n",
    "\n",
    "    # Description - string tipinə çevrilmə və təmizləmə\n",
    "    df['Description'] = df['Description'].fillna('')\n",
    "    df[\"Description\"] = df[\"Description\"].apply(lambda x: re.sub(r'[^\\w\\s,.!?()-]', '', str(x)))\n",
    "    df['Description'] = df['Description'].apply(lambda x: re.sub(r'[\\r\\n]+', '. ', x).strip())\n",
    "    df['Description'] = df['Description'].astype(\"string\")\n",
    "\n",
    "    # PricePerSqm - təmizləmə və integer-ə çevrilmə (NULL-larla)\n",
    "    df['PricePerSqm'] = df['PricePerSqm'].astype(\"string\").str.replace('AZN', '').str.replace(r'/m[²2]', '', regex=True).str.replace(' ', '')\n",
    "    df['PricePerSqm'] = pd.to_numeric(df['PricePerSqm'], errors='coerce')\n",
    "    df['PricePerSqm'] = df['PricePerSqm'].astype(\"Int64\") \n",
    "\n",
    "    # CategoryID - kategorik dəyərləri integer-ə çevirmə\n",
    "    df['CategoryID'] = df['CategoryID'].replace({\n",
    "        \"Mənzil\": 1, \n",
    "        \"Yeni tikili\": 2, \n",
    "        \"Köhnə tikili\": 3, \n",
    "        \"Həyət evi/bağ evi\": 4,\n",
    "        \"Həyət evi/Bağ evi\": 4,  # Həm kiçik həm böyük B variantı\n",
    "        \"Ofis\": 5, \n",
    "        \"Qaraj\": 6, \n",
    "        \"Torpaq\": 7, \n",
    "        \"Obyekt\": 8\n",
    "    })\n",
    "    df['CategoryID'] = pd.to_numeric(df['CategoryID'], errors='coerce')\n",
    "    df['CategoryID'] = df['CategoryID'].astype(\"Int64\")  # NULL-ları saxlayır\n",
    "\n",
    "\n",
    "    df[\"DailyRent\"] = df.apply(\n",
    "        lambda row: pd.NA if row[\"SalesType\"] == \"Satış\" else (\n",
    "            True if \"/gün\" in str(row[\"DailyRent\"]).lower() or \"/gun\" in str(row[\"DailyRent\"]).lower()\n",
    "            else False if \"/ay\" in str(row[\"DailyRent\"]).lower()\n",
    "            else pd.NA\n",
    "        ), axis=1\n",
    "    ).astype(\"boolean\")\n",
    "\n",
    "\n",
    "\n",
    "    # SalesType - kategorik dəyərləri integer-ə çevirmə\n",
    "    df['SalesType'] = df['SalesType'].replace({\"Kirayə\": 0, \"Satış\": 1})\n",
    "    df['SalesType'] = pd.to_numeric(df['SalesType'], errors='coerce')\n",
    "    df['SalesType'] = df['SalesType'].astype(\"Int64\")  # NULL-ları saxlayır\n",
    "\n",
    "    # FieldAreaSqm - təmizləmə və float-a çevrilmə\n",
    "    df['FieldAreaSqm'] = df['FieldAreaSqm'].astype(str).str.replace('m²', '', regex=False).str.strip()\n",
    "    df['FieldAreaSqm'] = pd.to_numeric(df['FieldAreaSqm'], errors='coerce')  # NULL-ları saxlayır\n",
    "\n",
    "    # CountRoom - integer tipinə çevrilmə\n",
    "    df['CountRoom'] = pd.to_numeric(df['CountRoom'], errors='coerce')\n",
    "    df['CountRoom'] = df['CountRoom'].astype(\"Int64\")  # NULL-ları saxlayır\n",
    "\n",
    "    # Floor - string tipinə çevrilmə və mərtəbə məlumatlarının ayrılması\n",
    "    df['Floor'] = df['Floor'].astype(\"string\")\n",
    "    # Floor sütunundan mərtəbə nömrəsi və ümumi mərtəbə sayı çıxarılması\n",
    "    df[['FloorNumber', 'TotalFloors']] = df['Floor'].apply(lambda x: pd.Series((\n",
    "        (lambda parts: (int(parts[0].strip()), int(parts[1].strip()) if len(parts) > 1 else None)\n",
    "        ) if x and '/' in x else (int(x.strip()), None)\n",
    "        )(str(x).split('/')) if pd.notna(x) and str(x).strip() != '' else (None, None)\n",
    "    ))\n",
    "\n",
    "    df['FloorNumber'] = df['FloorNumber'].astype(\"Int64\")\n",
    "    df['TotalFloors'] = df['TotalFloors'].astype(\"Int64\")\n",
    "    df = df.drop('Floor', axis=1)\n",
    "\n",
    "    # AreaInSot - float tipinə çevrilmə\n",
    "    df['AreaInSot'] = pd.to_numeric(df['AreaInSot'], errors='coerce')  \n",
    "\n",
    "    # Price - təmizləmə və integer-ə çevrilmə\n",
    "    df['Price'] = df['Price'].astype(str).str.replace(' ', '').str.replace(',', '')\n",
    "    df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "    df['Price'] = df['Price'].astype(\"Int64\")  \n",
    "\n",
    "    # String tipləri - NULL dəyərləri emal edilir\n",
    "    df['Residence'] = df['Residence'].fillna('').astype(\"string\")\n",
    "    df['Labels'] = df['Labels'].fillna('').astype(\"string\")\n",
    "    df['Agency'] = df['Agency'].fillna('').astype(\"string\")\n",
    "    df['URL'] = df['URL'].astype(\"string\")\n",
    "    df['BuildingType (ForOffice)'] = df['BuildingType (ForOffice)'].fillna('').astype(\"string\")\n",
    "    df['Currency'] = df['Currency'].astype(\"string\")\n",
    "    df['SalesPerson'] = df['SalesPerson'].astype(\"string\")\n",
    "\n",
    "\n",
    "    df['Address'] = df['Address'].fillna('')\n",
    "    df[\"Address\"] = df[\"Address\"].apply(lambda x: re.sub(r'[^\\w\\s,.!?()-]', '', str(x)))\n",
    "    df['Address'] = df['Address'].apply(lambda x: re.sub(r'[\\r\\n]+', '. ', x).strip())\n",
    "    df[\"Address\"] = df[\"Address\"].str.replace(\"User AgreementOpen in Yandex.Maps\", \"\", regex=False)\n",
    "    df[\"Address\"] = df[\"Address\"].str.replace(\"Yandex User AgreementDirections\", \"\", regex=False)\n",
    "    df[\"Address\"] = df[\"Address\"].str.replace(\"Ünvan\", \"\", regex=False)\n",
    "    df['Address'] = df['Address'].astype(\"string\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Şəhər adlarını ID-lərlə uyğunlaşdırmaq üçün xəritə (dictionary)\n",
    "    city_map = {\n",
    "        \"Ağcabədi\": 17, \"Ağdam\": 18, \"Ağdaş\": 19, \"Ağstafa\": 20, \"Ağsu\": 21,\n",
    "        \"Astara\": 22, \"Bakı\": 23, \"Balakən\": 24, \"Beyləqan\": 25, \"Bərdə\": 26,\n",
    "        \"Biləsuvar\": 27, \"Cəlilabad\": 28, \"Daşkəsən\": 29, \"Gədəbəy\": 30,\n",
    "        \"Gəncə\": 31, \"Göyçay\": 32, \"Göygöl\": 33, \"Hacıqabul\": 34, \"Xaçmaz\": 35,\n",
    "        \"Xankəndi\": 36, \"Xırdalan\": 37, \"Xızı\": 38, \"Xudat\": 39, \"İmişli\": 40,\n",
    "        \"İsmayıllı\": 41, \"Kürdəmir\": 42, \"Qax\": 43, \"Qazax\": 44, \"Qəbələ\": 45,\n",
    "        \"Qobustan\": 46, \"Quba\": 47, \"Qusar\": 48, \"Lerik\": 49, \"Lənkəran\": 50,\n",
    "        \"Masallı\": 51, \"Mingəçevir\": 52, \"Naxçıvan\": 53, \"Naxçıvan MR\": 54,\n",
    "        \"Neftçala\": 55, \"Oğuz\": 56, \"Saatlı\": 57, \"Sabirabad\": 58, \"Salyan\": 59,\n",
    "        \"Samux\": 60, \"Siyəzən\": 61, \"Sumqayıt\": 62, \"Şabran\": 63, \"Şamaxı\": 64,\n",
    "        \"Şəki\": 65, \"Şəmkir\": 66, \"Şirvan\": 67, \"Tərtər\": 68, \"Tovuz\": 69,\n",
    "        \"Ucar\": 70, \"Yardımlı\": 71, \"Yevlax\": 72, \"Zaqatala\": 73, \"Zərdab\": 74\n",
    "    }\n",
    "\n",
    "    # Əgər city_map-də tapılmazsa, default olaraq Bakı (23) ilə əvəz et.\n",
    "    df['CityID'] = df['CityID'].map(city_map).fillna(23).astype(int)\n",
    "\n",
    "    # ListingDate emalı - daha güvənli\n",
    "    df['ListingDate'] = df['ListingDate'].astype(\"string\").str.replace('Yeniləndi:', '', regex=True)\n",
    "\n",
    "    # Date və Time ayırması - xəta idarəsi ilə\n",
    "    try:\n",
    "        df[['Date', 'Time']] = df['ListingDate'].str.split(', ', expand=True)\n",
    "        df['Date'] = pd.to_datetime(df['Date'].str.strip(), format='%d.%m.%Y', errors='coerce')\n",
    "    except:\n",
    "        # Əgər tarix formatında problem varsa, sadəcə boş burax\n",
    "        df['Date'] = pd.NaT\n",
    "        df['Time'] = ''\n",
    "\n",
    "    df = df.drop('ListingDate', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------\n",
    "    metro_mapping = {\n",
    "        \"20 Yanvar\":1, \"28 May\":2, \"8 Noyabr\":3, \"Avtovağzal\":4, \"Azadlıq Prospekti\":5, \"Bakmil\":6,\n",
    "        \"Dərnəgül\":7, \"Elmlər Akademiyası\":8, \"Əhmədli\":9, \"Gənclik\":10, \"Həzi Aslanov\":11,\n",
    "        \"İçəri Şəhər\":12, \"İnşaatçılar\":13, \"Koroğlu\":14, \"Memar Əcəmi\":15, \"Nəriman Nərimanov\":16,\n",
    "        \"Nəsimi\":17, \"Neftçilər\":18, \"Nizami\":19, \"Qara Qarayev\":20, \"Sahil\":21,\n",
    "        \"Şah İsmayıl Xətai\":22, \"Xalqlar Dostluğu\":23, \"Xocəsən\":24, \"Ulduz\":25, \"Cəfər Cabbarlı\":26}\n",
    "\n",
    "    settlement_mapping = {\n",
    "        \"Abşeron r.\":1, \"Aşağı Güzdək\":2, \"Atyalı\":3, \"Ceyranbatan\":4, \"Çiçək\":5, \"Digah\":6,\n",
    "        \"Fatmayı\":7, \"Görədil\":8, \"Hökməli\":9, \"Köhnə Corat\":10, \"Qobu\":11, \"Masazır\":12,\n",
    "        \"Mehdiabad\":13, \"Məmmədli\":14, \"Novxanı\":15, \"Pirəkəşkül\":16, \"Saray\":17, \"Yeni Corat\":18,\n",
    "        \"Zuğulba\":19, \"Binəqədi r.\":20, \"2-ci Alatava\":21, \"28 May\":22, \"6-cı mikrorayon\":23,\n",
    "        \"7-ci mikrorayon\":24, \"8-ci mikrorayon\":25, \"9-cu mikrorayon\":26, \"Biləcəri\":27,\n",
    "        \"Binəqədi\":28, \"Xocəsən\":29, \"Xutor\":30, \"M.Ə.Rəsulzadə\":31, \"Sulutəpə\":32,\n",
    "        \"Xətai r.\":33, \"Ağ şəhər\":34, \"Əhmədli\":35, \"Həzi Aslanov\":36, \"Köhnə Günəşli\":37,\n",
    "        \"NZS\":38, \"Xəzər r.\":39, \"Binə\":40, \"Buzovna\":41, \"Dübəndi\":42, \"Gürgən\":43,\n",
    "        \"Qala\":44, \"Mərdəkan\":45, \"Şağan\":46, \"Şimal DRES\":47, \"Şüvəlan\":48, \"Türkan\":49,\n",
    "        \"Zirə\":50, \"Qaradağ r.\":51, \"Ələt\":52, \"Qızıldaş\":53, \"Qobustan\":54, \"Lökbatan\":55,\n",
    "        \"Müşfiqabad\":56, \"Puta\":57, \"Sahil\":58, \"Səngəçal\":59, \"Şubanı\":60, \"Nərimanov r.\":61,\n",
    "        \"Böyükşor\":62, \"Nəsimi r.\":63, \"1-ci mikrorayon\":64, \"2-ci mikrorayon\":65, \"3-cü mikrorayon\":66,\n",
    "        \"4-cü mikrorayon\":67, \"5-ci mikrorayon\":68, \"Kubinka\":69, \"Nizami r.\":70, \"8-ci kilometr\":71,\n",
    "        \"Keşlə\":72, \"Pirallahı r.\":73, \"Sabunçu r.\":74, \"Albalılıq\":75, \"Bakıxanov\":76,\n",
    "        \"Balaxanı\":77, \"Bilgəh\":78, \"Kürdəxanı\":79, \"Maştağa\":80, \"Nardaran\":81, \"Pirşağı\":82,\n",
    "        \"Ramana\":83, \"Sabunçu\":84, \"Savalan\":85, \"Yeni Balaxanı\":86, \"Yeni Ramana\":87, \"Zabrat\":88,\n",
    "        \"Səbail r.\":89, \"20-ci sahə\":90, \"Badamdar\":91, \"Bayıl\":92, \"Bibiheybət\":93, \"Şıxov\":94,\n",
    "        \"Suraxanı r.\":95, \"Bahar\":96, \"Bülbülə\":97, \"Dədə Qorqud\":98, \"Əmircan\":99, \"Günəşli\":100,\n",
    "        \"Hövsan\":101, \"Qaraçuxur\":102, \"Massiv A\":103, \"Massiv B\":104, \"Massiv D\":105,\n",
    "        \"Massiv G\":106, \"Massiv V\":107, \"Suraxanı\":108, \"Şərq\":109, \"Yeni Günəşli\":110,\n",
    "        \"Yeni Suraxanı\":111, \"Zığ\":112, \"Yasamal r.\":113, \"Yasamal\":114, \"Yeni Yasamal\":115, \"Albalılıq\":131}\n",
    "\n",
    "    # \\xa0 əvəzinə boşluq\n",
    "    df['ListingName'] = df['ListingName'].str.replace('\\xa0', ' ', regex=False)\n",
    "\n",
    "    # Metro adını çıxart\n",
    "    df['MetroName'] = df['ListingName'].str.extract(r',\\s*([\\w\\s\\-çğıöşüÇĞİÖŞÜƏ\\.]+?)\\s+m\\.', expand=False).str.strip()\n",
    "\n",
    "    # Metro mapping-ə uyğun MetroID tap\n",
    "    df['MetroID'] = df['MetroName'].map(metro_mapping)\n",
    "\n",
    "    # Settlement adını çıxart\n",
    "    df['SettlementName'] = df['ListingName'].str.extract(r',\\s*([\\w\\s\\-çğıöşüÇĞİÖŞÜƏ\\.]+?)\\s+[rq]\\.', expand=False).str.strip()\n",
    "\n",
    "    # Mapping üçün uyğunlaşdırılmış ad sütunu (sonluqları əlavə edirik)\n",
    "    df['SettlementMatch'] = df['SettlementName'].apply(lambda x: \n",
    "        f\"{x} r.\" if f\"{x} r.\" in settlement_mapping else (\n",
    "            f\"{x} q.\" if f\"{x} q.\" in settlement_mapping else x\n",
    "        ) if pd.notna(x) else x)\n",
    "\n",
    "    # SettlementID tap\n",
    "    df['SettlementsID'] = df['SettlementMatch'].map(settlement_mapping)\n",
    "\n",
    "    # Təmizləmə: artıq sütunları sil\n",
    "    df.drop(columns=['MetroName', 'SettlementName', 'SettlementMatch'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def cleaner():\n",
    "    while True:\n",
    "        raw = raw_data.get()        \n",
    "        cleaned = preprocess(raw)        \n",
    "        cleaned_data.put(cleaned)       \n",
    "        raw_data.task_done()\n",
    "\n",
    "\n",
    "\n",
    "def inserter():\n",
    "    while True:\n",
    "        cleaned = cleaned_data.get()\n",
    "        insert_data(cleaned)\n",
    "        cleaned_data.task_done()\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Insert Database\n",
    "def insert_data(df):    \n",
    "    # Database bağlantısı\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "            \"SERVER=DESKTOP-KIDL0VQ\\\\SQLEXPRESS;\" \n",
    "            \"DATABASE=RealEstateDB;\"\n",
    "            \"Trusted_Connection=yes;\")\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Database Connection\")\n",
    "    except Exception as e:\n",
    "        print(f\"Database Connect Xeta: {e}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Orijinal məlumat sayı: {len(df)}\")\n",
    "    df = df.drop_duplicates(subset=['ListingID'])\n",
    "    print(f\"Dublikatlar silindikdən sonra: {len(df)}\")\n",
    "\n",
    "    # null deyerleri ucun\n",
    "    def safe_value(value):\n",
    "        if pd.isna(value):\n",
    "            return None\n",
    "        return value\n",
    "\n",
    "    # datalar database-de yoxlanir\n",
    "    def is_listing_exists(listing_id, table_name):\n",
    "        try:\n",
    "            query = f\"SELECT COUNT(*) FROM Dynamic.{table_name} WHERE ListingID = ?\"\n",
    "            cursor.execute(query, (listing_id,))\n",
    "            result = cursor.fetchone()\n",
    "            return result[0] > 0\n",
    "        except Exception as e:\n",
    "            print(f\"Yoxlama xətası {table_name} - {listing_id}: {e}\")\n",
    "            return False\n",
    "\n",
    "    stats = {\n",
    "        'apartment': 0,\n",
    "        'house': 0,\n",
    "        'office': 0,\n",
    "        'garage': 0,\n",
    "        'land': 0,\n",
    "        'commercial': 0,\n",
    "        'estate_listing': 0,\n",
    "        'seller_info': 0,\n",
    "        'url': 0,\n",
    "        'labels': 0,\n",
    "        'description': 0,\n",
    "        'listing_images': 0 }\n",
    "\n",
    "    try:        \n",
    "        estate_query = \"\"\"\n",
    "        INSERT INTO Dynamic.EstateListing (ListingID, ListingName, SalesType, DailyRent, CategoryID, SellerType, Price, PricePerSqm, Currency, CityID, Address, Date, Time, MetroID, SettlementsID, Latitude, Longitude)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            \n",
    "            if not is_listing_exists(listing_id, \"EstateListing\"):\n",
    "                try:\n",
    "                    cursor.execute(estate_query, (listing_id,\n",
    "                        safe_value(row.get(\"ListingName\")),\n",
    "                        safe_value(row.get(\"SalesType\")),\n",
    "                        safe_value(row.get(\"DailyRent\")),\n",
    "                        safe_value(row.get(\"CategoryID\")),\n",
    "                        safe_value(row.get(\"SellerType\")),\n",
    "                        safe_value(row.get(\"Price\")),\n",
    "                        safe_value(row.get(\"PricePerSqm\")),\n",
    "                        safe_value(row.get(\"Currency\")),\n",
    "                        safe_value(row.get(\"CityID\")),\n",
    "                        safe_value(row.get(\"Address\")),\n",
    "                        safe_value(row.get(\"Date\")),\n",
    "                        safe_value(row.get(\"Time\")),\n",
    "                        safe_value(row.get(\"MetroID\")),\n",
    "                        safe_value(row.get(\"SettlementsID\")),\n",
    "                        safe_value(row.get(\"Latitude\")),\n",
    "                        safe_value(row.get(\"Longitude\"))))\n",
    "                    stats['estate_listing'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\" X EstateListing {listing_id} xətası: {e}\")\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        seller_query = \"\"\"\n",
    "        INSERT INTO Dynamic.SellerInfo (ListingID, ListingName, Contact, SellerType, Agency, Residence)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"SellerInfo\"):\n",
    "                try:\n",
    "                    cursor.execute(seller_query, (\n",
    "                        listing_id,\n",
    "                        safe_value(row.get(\"ListingName\")),\n",
    "                        safe_value(row.get(\"Contact\")),\n",
    "                        safe_value(row.get(\"SellerType\")),\n",
    "                        safe_value(row.get(\"Agency\")),\n",
    "                        safe_value(row.get(\"Residence\"))\n",
    "                    ))\n",
    "                    stats['seller_info'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ SellerInfo {listing_id} xətası: {e}\")\n",
    "\n",
    "        description_query = \"\"\"\n",
    "        INSERT INTO Dynamic.Description (ListingID, Description)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Description\"):\n",
    "                try:\n",
    "                    cursor.execute(description_query, (\n",
    "                        listing_id,\n",
    "                        safe_value(row.get(\"Description\"))\n",
    "                    ))\n",
    "                    stats['description'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  ✗ Description {listing_id} xətası: {e}\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        if df[\"CategoryID\"].isin([1, 2, 3]).any():\n",
    "            apartment_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Apartment (ListingID, CategoryID, FloorNumber, TotalFloors, FieldAreaSqm, CountRoom, Title, Mortgage, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_apartments = df[df[\"CategoryID\"].isin([1, 2, 3])]\n",
    "            \n",
    "            for index, row in df_apartments.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Apartment\"):\n",
    "                    try:\n",
    "                        cursor.execute(apartment_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FloorNumber\")),\n",
    "                            safe_value(row.get(\"TotalFloors\")),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"CountRoom\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Mortgage\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['apartment'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\" X Apartment {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 4).any():\n",
    "            house_query = \"\"\"\n",
    "            INSERT INTO Dynamic.House (ListingID, CategoryID, FieldAreaSqm, AreaInSot, CountRoom, Mortgage, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_house = df[df[\"CategoryID\"] == 4]\n",
    "            \n",
    "            for index, row in df_house.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"House\"):\n",
    "                    try:\n",
    "                        cursor.execute(house_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"AreaInSot\")),\n",
    "                            safe_value(row.get(\"CountRoom\")),\n",
    "                            safe_value(row.get(\"Mortgage\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['house'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"X House {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 5).any():\n",
    "            office_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Office (ListingID, CategoryID, FieldAreaSqm, [BuildingType (ForOffice)], CountRoom, Title, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_office = df[df[\"CategoryID\"] == 5]\n",
    "            \n",
    "            for index, row in df_office.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Office\"):\n",
    "                    try:\n",
    "                        cursor.execute(office_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"BuildingType (ForOffice)\")),\n",
    "                            safe_value(row.get(\"CountRoom\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['office'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\" X Office {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 6).any():\n",
    "            garage_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Garage (ListingID, CategoryID, FieldAreaSqm, Title)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_garage = df[df[\"CategoryID\"] == 6]\n",
    "            \n",
    "            for index, row in df_garage.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Garage\"):\n",
    "                    try:\n",
    "                        cursor.execute(garage_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"Title\"))))\n",
    "                        stats['garage'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\" X Garage {listing_id} xətası: {e}\")\n",
    "\n",
    "\n",
    "        if (df[\"CategoryID\"] == 7).any():\n",
    "            land_query = \"\"\"\n",
    "            INSERT INTO Dynamic.Land (ListingID, CategoryID, FieldAreaSqm, Title, Mortgage)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_land = df[df[\"CategoryID\"] == 7]\n",
    "            \n",
    "            for index, row in df_land.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"Land\"):\n",
    "                    try:\n",
    "                        cursor.execute(land_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Mortgage\")))) \n",
    "                        stats['land'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"X Land {listing_id} xətası: {e}\")\n",
    "\n",
    "        if (df[\"CategoryID\"] == 8).any():\n",
    "            commercial_query = \"\"\"\n",
    "            INSERT INTO Dynamic.CommercialProperty (ListingID, CategoryID, FieldAreaSqm, Title, Mortgage, Repaired)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            df_commercial = df[df[\"CategoryID\"] == 8]\n",
    "            \n",
    "            for index, row in df_commercial.iterrows():\n",
    "                listing_id = safe_value(row[\"ListingID\"])\n",
    "                if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"CommercialProperty\"):\n",
    "                    try:\n",
    "                        cursor.execute(commercial_query, (listing_id,\n",
    "                            safe_value(row[\"CategoryID\"]),\n",
    "                            safe_value(row.get(\"FieldAreaSqm\")),\n",
    "                            safe_value(row.get(\"Title\")),\n",
    "                            safe_value(row.get(\"Mortgage\")),\n",
    "                            safe_value(row.get(\"Repaired\"))))\n",
    "                        stats['commercial'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"X Commercial Property {listing_id} xətası: {e}\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "        # URL\n",
    "        url_query = \"\"\"\n",
    "        INSERT INTO Dynamic.URL (ListingID, URL)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\") and not is_listing_exists(listing_id, \"URL\"):\n",
    "                try:\n",
    "                    cursor.execute(url_query, (\n",
    "                        listing_id,\n",
    "                        safe_value(row.get(\"URL\"))\n",
    "                    ))\n",
    "                    stats['url'] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\" X URL {listing_id} xətası: {e}\")\n",
    "\n",
    "\n",
    "        labels_query = \"\"\"\n",
    "        INSERT INTO Dynamic.Labels (ListingID, Labels)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "\n",
    "        def is_listing_label_exists(listing_id, label):\n",
    "            check_query = \"SELECT 1 FROM Dynamic.Labels WHERE ListingID = ? AND Labels = ?\"\n",
    "            cursor.execute(check_query, (listing_id, label))\n",
    "            return cursor.fetchone() is not None\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\"):\n",
    "                labels_raw = row.get(\"Labels\", \"\")\n",
    "                \n",
    "                labels_list = []\n",
    "                if labels_raw:\n",
    "                    if isinstance(labels_raw, str):\n",
    "                        clean_str = str(labels_raw).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "                        labels_list = [x.strip() for x in clean_str.split(\",\") if x.strip()]\n",
    "                    elif isinstance(labels_raw, list):\n",
    "                        labels_list = [str(x).strip() for x in labels_raw if str(x).strip()]\n",
    "                \n",
    "                for label in labels_list:\n",
    "                    if not is_listing_label_exists(listing_id, label):\n",
    "                        try:\n",
    "                            cursor.execute(labels_query, (listing_id, label))\n",
    "                            stats['labels'] += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\" X Labels {listing_id} ({label}) xətası: {e}\")\n",
    "\n",
    "\n",
    "        def is_image_exists(image_url):\n",
    "            try:\n",
    "                check_query = \"SELECT COUNT(*) FROM Dynamic.ListingImages WHERE ImageURL = ?\"\n",
    "                cursor.execute(check_query, (image_url,))\n",
    "                result = cursor.fetchone()\n",
    "                return result[0] > 0\n",
    "            except Exception as e:\n",
    "                print(f\"Image yoxlama xətası: {e}\")\n",
    "                return False\n",
    "\n",
    "        listing_images_query = \"\"\"\n",
    "        INSERT INTO Dynamic.ListingImages (ListingID, ImageURL)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "\n",
    "        processed_images = set()\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            listing_id = safe_value(row[\"ListingID\"])\n",
    "            if is_listing_exists(listing_id, \"EstateListing\"):\n",
    "                image_links = row.get(\"Images\")\n",
    "                \n",
    "                if image_links and listing_id:\n",
    "                    if isinstance(image_links, str):\n",
    "                        try:\n",
    "                            import json\n",
    "                            image_list = json.loads(image_links)\n",
    "                        except:\n",
    "                            image_list = [link.strip() for link in image_links.split(',') if link.strip()]\n",
    "                    elif isinstance(image_links, list):\n",
    "                        image_list = image_links\n",
    "                    else:\n",
    "                        image_list = []\n",
    "                    \n",
    "                    for image_url in image_list:\n",
    "                        image_url_clean = safe_value(image_url)\n",
    "                        \n",
    "                        if image_url_clean and image_url_clean not in processed_images:\n",
    "                            if not is_image_exists(image_url_clean):\n",
    "                                try:\n",
    "                                    cursor.execute(listing_images_query, (\n",
    "                                        listing_id,\n",
    "                                        image_url_clean\n",
    "                                    ))\n",
    "                                    stats['listing_images'] += 1\n",
    "                                    processed_images.add(image_url_clean)\n",
    "                                except Exception as e:\n",
    "                                    print(f\"X Image {listing_id} xətası: {e}\")\n",
    "\n",
    "        # Final commit\n",
    "        conn.commit()\n",
    "        print(\"Uğurlu\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ümumi xəta baş verdi: {e}\")\n",
    "        try:\n",
    "            conn.rollback()\n",
    "            print(\"Rollback edildi\")\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        try:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"Database bağlantısı bağlandı\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Nəticələr\n",
    "    print(f\"   EstateListing: {stats['estate_listing']}\")\n",
    "    print(f\"   SellerInfo:    {stats['seller_info']}\")\n",
    "    print(f\"   Description:   {stats['description']}\")\n",
    "    print(f\"   Apartment:     {stats['apartment']}\")\n",
    "    print(f\"   House:         {stats['house']}\")\n",
    "    print(f\"   Office:        {stats['office']}\")\n",
    "    print(f\"   Garage:        {stats['garage']}\")\n",
    "    print(f\"   Land:          {stats['land']}\")\n",
    "    print(f\"   Commercial:    {stats['commercial']}\")\n",
    "    print(f\"   URL:           {stats['url']}\")\n",
    "    print(f\"   Labels:        {stats['labels']}\")\n",
    "    print(f\"   Images:        {stats['listing_images']}\")\n",
    "    print(f\"   TOPLAM:        {sum(stats.values())}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Thread(target=scrap, daemon=True).start()\n",
    "    Thread(target=cleaner, daemon=True).start()\n",
    "    Thread(target=inserter, daemon=True).start()\n",
    "\n",
    "    # Prosesi aciq saxlamaq ucun\n",
    "    raw_data.join()\n",
    "    cleaned_data.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
